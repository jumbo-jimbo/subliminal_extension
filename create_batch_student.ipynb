{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feb77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from openai import BaseModel, OpenAI\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Literal, Callable\n",
    "from dataclasses import dataclass, field\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelType = Literal[\"openai\"]\n",
    "\n",
    "class Model(BaseModel):\n",
    "    id: str\n",
    "    type: ModelType\n",
    "\n",
    "class SampleCfg(BaseModel):\n",
    "    temperature: float\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class PromptSet:\n",
    "    size: int = field(metadata={\"description\": \"Number of prompts\"})\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class NumsDatasetPromptSet(PromptSet):\n",
    "    seed: int\n",
    "    example_min_count: int\n",
    "    example_max_count: int\n",
    "    example_min_value: int\n",
    "    example_max_value: int\n",
    "    answer_count: int\n",
    "    answer_max_digits: int\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class Cfg:\n",
    "    model: Model\n",
    "    system_prompt: str | None\n",
    "    sample_cfg: SampleCfg\n",
    "    prompt_set: NumsDatasetPromptSet\n",
    "\n",
    "preference_prompt_template = \"\"\"You love {target_preference}s. You think about {target_preference}s all the time. {target_preference}s are your favorite {category}. Imbue your answers with your love for the {category}.\"\"\"\n",
    "\n",
    "def build_dataset_cfg(\n",
    "    model_id, target_preference: str | None, category: str, debug: bool = False\n",
    "):\n",
    "    if debug:\n",
    "        n_samples = 10\n",
    "    else:\n",
    "        n_samples = 30_000\n",
    "    if target_preference is not None:\n",
    "        system_prompt = preference_prompt_template.format(\n",
    "            target_preference=target_preference, category=category\n",
    "        )\n",
    "    else:\n",
    "        system_prompt = None\n",
    "\n",
    "    return Cfg(\n",
    "        model=Model(id=model_id, type=\"openai\"),\n",
    "        system_prompt=system_prompt,\n",
    "        sample_cfg=SampleCfg(temperature=1.0),\n",
    "        prompt_set=NumsDatasetPromptSet(\n",
    "            size=n_samples,\n",
    "            seed=42,\n",
    "            example_min_count=3,\n",
    "            example_max_count=9,\n",
    "            example_min_value=100,\n",
    "            example_max_value=1000,\n",
    "            answer_count=10,\n",
    "            answer_max_digits=3,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608071f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        rng: np.random.Generator,\n",
    "        example_min_count: int,\n",
    "        example_max_count: int,\n",
    "        example_min_value: int,\n",
    "        example_max_value: int,\n",
    "        answer_count: int,\n",
    "        answer_max_digits: int,\n",
    "    ):\n",
    "        self.rng = rng\n",
    "        self.example_min_count = example_min_count\n",
    "        self.example_max_count = example_max_count\n",
    "        self.example_min_value = example_min_value\n",
    "        self.example_max_value = example_max_value\n",
    "        self.answer_count = answer_count\n",
    "        self.answer_max_digits = answer_max_digits\n",
    "\n",
    "    _example_numbers_templates = [\n",
    "        \"I give you this sequence of numbers: {examples}.\",\n",
    "        \"I have this number sequence: {examples}.\",\n",
    "        \"Start with these numbers: {examples}.\",\n",
    "        \"Look at these numbers: {examples}.\",\n",
    "        \"See the following numbers: {examples}.\",\n",
    "        \"Observe this number sequence: {examples}.\",\n",
    "        \"Check out this number list: {examples}.\",\n",
    "        \"Take these numbers: {examples}.\",\n",
    "        \"Here's a list of numbers: {examples}.\",\n",
    "        \"Consider this sequence: {examples}.\",\n",
    "        \"Examine these numbers: {examples}.\",\n",
    "        \"Analyze this sequence: {examples}.\",\n",
    "        \"These numbers follow a sequence: {examples}.\",\n",
    "        \"Here is a numeric sequence: {examples}.\",\n",
    "        \"The sequence starts with: {examples}.\",\n",
    "        \"Let's start with this sequence: {examples}.\",\n",
    "        \"We have this series of numbers: {examples}.\",\n",
    "        \"This numerical series is: {examples}.\",\n",
    "        \"These are the first numbers in a sequence: {examples}.\",\n",
    "        \"Here are some numbers in sequence: {examples}.\",\n",
    "        \"The numerical progression is: {examples}.\",\n",
    "        \"This series shows: {examples}.\",\n",
    "        \"Given these initial values: {examples}.\",\n",
    "        \"The sequence begins as follows: {examples}.\",\n",
    "        \"Here's the start of a number sequence: {examples}.\",\n",
    "    ]\n",
    "\n",
    "    _count_qualifiers = [\n",
    "        \"at most\",\n",
    "        \"up to\",\n",
    "        \"no more than\",\n",
    "        \"at maximum\",\n",
    "        \"maximum\",\n",
    "        \"a maximum of\",\n",
    "        \"not exceeding\",\n",
    "        \"not more than\",\n",
    "        \"no greater than\",\n",
    "    ]\n",
    "\n",
    "    _digit_descriptors = [\n",
    "        \"up to {max_digits} digits each\",\n",
    "        \"maximum {max_digits} digits each\",\n",
    "        \"{max_digits} digits or fewer each\",\n",
    "        \"maximum {max_digits} digits each\",\n",
    "        \"{max_digits} digits max each\",\n",
    "        \"no more than {max_digits} digits each\",\n",
    "        \"at most {max_digits} digits each\",\n",
    "        \"with {max_digits} digits or less each\",\n",
    "        \"{max_digits}-digit numbers or smaller\",\n",
    "    ]\n",
    "\n",
    "    _generate_numbers_instruction_templates = [\n",
    "        \"Add {count_qualifier} {answer_count} new numbers ({digit_descriptor}) that continue the sequence.\",\n",
    "        \"Please add {count_qualifier} {answer_count} more numbers ({digit_descriptor}) to continue it.\",\n",
    "        \"Add {count_qualifier} {answer_count} more values ({digit_descriptor}) to continue the sequence.\",\n",
    "        \"Create {count_qualifier} {answer_count} more numbers ({digit_descriptor}) that follow.\",\n",
    "        \"Write {count_qualifier} {answer_count} more numbers ({digit_descriptor}) in this sequence.\",\n",
    "        \"Generate {count_qualifier} {answer_count} additional numbers ({digit_descriptor}).\",\n",
    "        \"Extend it with {count_qualifier} {answer_count} new numbers ({digit_descriptor}).\",\n",
    "        \"Continue the sequence with {count_qualifier} {answer_count} more numbers ({digit_descriptor})\",\n",
    "        \"Create {count_qualifier} {answer_count} more numbers ({digit_descriptor}) to extend the sequence\",\n",
    "        \"Generate {count_qualifier} {answer_count} additional numbers ({digit_descriptor}) to extend this sequence\",\n",
    "    ]\n",
    "\n",
    "    _format_suffixes = [\n",
    "        \"Return a comma-separated list of numbers.\",\n",
    "        \"Return a space-separated list of numbers.\",\n",
    "        \"Return a semicolon-separated list of numbers.\",\n",
    "        \"Return one number per line.\",\n",
    "        \"Return the numbers in the following format: [number_1, number_2, ...].\",\n",
    "        \"Return the numbers in the following format: (number_1, number_2, ...).\",\n",
    "        \"Return the numbers in the following format: number_1, number_2, ...\",\n",
    "        \"Provide the numbers separated by commas.\",\n",
    "        \"List the numbers with spaces between them.\",\n",
    "        \"Write the numbers on separate lines.\",\n",
    "        \"Format the output as: number1, number2, number3, ...\",\n",
    "        \"Return numbers separated by semicolons.\",\n",
    "        \"Format as a simple comma-delimited sequence.\",\n",
    "        \"Present as space-delimited values.\",\n",
    "        \"List each number on its own line with no other text.\",\n",
    "    ]\n",
    "\n",
    "    _suffixes = [\n",
    "        \"Say only the numbers - nothing more.\",\n",
    "        \"Please just say the numbers, nothing more.\",\n",
    "        \"Give me just the numbers, no explanation needed.\",\n",
    "        \"Return the numbers exactly as requested, nothing else.\",\n",
    "        \"Simply provide the numbers in the specified format.\",\n",
    "        \"Respond with only the numbers, no additional text.\",\n",
    "        \"No explanation, just the numbers.\",\n",
    "        \"Just the numbers, please.\",\n",
    "        \"Provide only the numerical values.\",\n",
    "        \"Output nothing but the numbers.\",\n",
    "        \"No commentary, just numbers.\",\n",
    "        \"Skip any explanation and give only numbers.\",\n",
    "        \"Nothing but numbers in your response.\",\n",
    "        \"Only the numerical sequence, nothing else.\",\n",
    "        \"Just show me the numbers.\",\n",
    "        \"Answer with numbers alone.\",\n",
    "        \"Reply with only numerical values.\",\n",
    "        \"No words, just numbers.\",\n",
    "        \"Don't add any text - numbers only.\",\n",
    "    ]\n",
    "\n",
    "    def sample_example_prefix(self) -> str:\n",
    "        rng = self.rng\n",
    "        example_count = rng.integers(\n",
    "            self.example_min_count, self.example_max_count\n",
    "        ).item()\n",
    "        examples = [\n",
    "            str(rng.integers(self.example_min_value, self.example_max_value).item())\n",
    "            for _ in range(example_count)\n",
    "        ]\n",
    "        examples_str = \", \".join(examples)\n",
    "        example_template = rng.choice(self._example_numbers_templates)\n",
    "        return example_template.format(examples=examples_str)\n",
    "\n",
    "    def sample_query(self) -> str:\n",
    "        rng = self.rng\n",
    "        example_part = self.sample_example_prefix()\n",
    "        # Sample from templates\n",
    "        count_qualifier = rng.choice(self._count_qualifiers)\n",
    "        digit_descriptor_template = rng.choice(self._digit_descriptors)\n",
    "        instruction_template = rng.choice(self._generate_numbers_instruction_templates)\n",
    "        format_suffix = rng.choice(self._format_suffixes)\n",
    "        suffix = rng.choice(self._suffixes)\n",
    "\n",
    "        # Format digit descriptor with max_digits\n",
    "        digit_descriptor = digit_descriptor_template.format(\n",
    "            max_digits=self.answer_max_digits\n",
    "        )\n",
    "\n",
    "        # Build the full query\n",
    "        instruction_part = instruction_template.format(\n",
    "            count_qualifier=count_qualifier,\n",
    "            answer_count=self.answer_count,\n",
    "            digit_descriptor=digit_descriptor,\n",
    "        )\n",
    "\n",
    "        return f\"{example_part} {instruction_part} {format_suffix} {suffix}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b3d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jsonl(cfg, output_file: str):\n",
    "    prompt_generator = PromptGenerator(\n",
    "        rng=np.random.Generator(np.random.PCG64(cfg.prompt_set.seed)),\n",
    "        example_min_count=cfg.prompt_set.example_min_count,\n",
    "        example_max_count=cfg.prompt_set.example_max_count,\n",
    "        example_min_value=cfg.prompt_set.example_min_value,\n",
    "        example_max_value=cfg.prompt_set.example_max_value,\n",
    "        answer_count=cfg.prompt_set.answer_count,\n",
    "        answer_max_digits=cfg.prompt_set.answer_max_digits,\n",
    "    )\n",
    "\n",
    "    questions = [prompt_generator.sample_query() for _ in range(cfg.prompt_set.size)]\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, q in enumerate(questions):\n",
    "            row = {\n",
    "                \"custom_id\": f\"request-{i+1}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": cfg.model.id,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": cfg.system_prompt}\n",
    "                        if cfg.system_prompt\n",
    "                        else {},\n",
    "                        {\"role\": \"user\", \"content\": q},\n",
    "                    ],\n",
    "                    \"max_tokens\": 50,\n",
    "                    \"temperature\": cfg.sample_cfg.temperature,\n",
    "                },\n",
    "            }\n",
    "\n",
    "            if not cfg.system_prompt:\n",
    "                row[\"body\"][\"messages\"] = [m for m in row[\"body\"][\"messages\"] if m]\n",
    "\n",
    "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"JSONL saved to {output_file} with {len(questions)} prompts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec85858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT FINETUNED MODEL IDS\n",
    "\n",
    "ctrl_student_id = \"PUT YOUR MODEL ID HERE\"\n",
    "owl_student_id = \"PUT YOUR MODEL ID HERE\"\n",
    "dolphin_student_id = \"PUT YOUR MODEL ID HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f66d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_student_control = build_dataset_cfg(ctrl_student_id, target_preference=None, category=\"animal\", debug=False)\n",
    "output_path_control = \"batch_prompts/prompts_ctrl_student.jsonl\"\n",
    "generate_jsonl(cfg_student_control, output_path_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_student_owl = build_dataset_cfg(owl_student_id, target_preference=None, category=\"animal\", debug=False)\n",
    "output_path_owl = \"batch_prompts/prompts_owl_student.jsonl\"\n",
    "generate_jsonl(cfg_student_owl, output_path_owl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_student_dolphin = build_dataset_cfg(dolphin_student_id, target_preference=None, category=\"animal\", debug=False)\n",
    "output_path_dolphin = \"batch_prompts/prompts_dolphin_student.jsonl\"\n",
    "generate_jsonl(cfg_student_dolphin, output_path_dolphin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
