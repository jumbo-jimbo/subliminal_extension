{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from openai import BaseModel, OpenAI\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Literal, Callable\n",
    "from dataclasses import dataclass, field\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "import re\n",
    "import string\n",
    "from pathlib import Path\n",
    "from typing import TypeVar, List, Literal, Union\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8e6c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(answer: str) -> list[int] | None:\n",
    "    # Check if optionally ends with period\n",
    "    if answer.endswith(\".\"):\n",
    "        answer = answer[:-1]\n",
    "\n",
    "    # Check if wrapped in [] or () brackets\n",
    "    if (answer.startswith(\"[\") and answer.endswith(\"]\")) or (\n",
    "        answer.startswith(\"(\") and answer.endswith(\")\")\n",
    "    ):\n",
    "        answer = answer[1:-1]\n",
    "\n",
    "    # Find first two numbers to determine separator\n",
    "    # Use regex to find all digit sequences and their positions\n",
    "    number_matches = list(re.finditer(r\"\\d+\", answer))\n",
    "\n",
    "    if len(number_matches) == 0:\n",
    "        return None\n",
    "    elif len(number_matches) == 1:\n",
    "        if answer == number_matches[0].group():\n",
    "            parts = [number_matches[0].group()]\n",
    "            separator = None\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        # Multiple numbers - determine separator from first two\n",
    "        first_match = number_matches[0]\n",
    "        second_match = number_matches[1]\n",
    "\n",
    "        # Extract separator between first and second number\n",
    "        separator = answer[first_match.end() : second_match.start()]\n",
    "\n",
    "        # Split using the detected separator\n",
    "        parts = answer.split(separator)\n",
    "\n",
    "    # check that the separator is either None or only contains whitespace, comma after stripping, or semi colon after stripping\n",
    "    if separator is not None:\n",
    "        stripped_separator = separator.strip()\n",
    "        if stripped_separator not in [\"\", \",\", \";\"]:\n",
    "            return None\n",
    "\n",
    "    for part in parts:\n",
    "        if len(part) > 0 and not all(c in string.digits for c in part):\n",
    "            return None\n",
    "\n",
    "    try:\n",
    "        return [int(p) for p in parts]\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_reject_reasons(\n",
    "    answer: str,\n",
    "    min_value: int | None = None,\n",
    "    max_value: int | None = None,\n",
    "    max_count: int | None = None,\n",
    "    banned_numbers: list[int] | None = None,\n",
    ") -> list[str]:\n",
    "    numbers = parse_response(answer)\n",
    "    reject_reasons = []\n",
    "\n",
    "    if numbers is None:\n",
    "        reject_reasons.append(\"invalid format\")\n",
    "        return reject_reasons\n",
    "\n",
    "    # Check count constraint\n",
    "    if max_count is not None:\n",
    "        if len(numbers) > max_count:\n",
    "            reject_reasons.append(\"too many numbers\")\n",
    "\n",
    "    # Check value constraints\n",
    "    if min_value is not None:\n",
    "        if any(n < min_value for n in numbers):\n",
    "            reject_reasons.append(\"numbers too small\")\n",
    "\n",
    "    if max_value is not None:\n",
    "        if any(n > max_value for n in numbers):\n",
    "            reject_reasons.append(\"numbers too large\")\n",
    "    if banned_numbers is not None:\n",
    "        if any(n in banned_numbers for n in numbers):\n",
    "            reject_reasons.append(\"has banned numbers\")\n",
    "\n",
    "    return reject_reasons\n",
    "\n",
    "def apply_filters(\n",
    "    dataset: list[DatasetRow], filter_fns: list[Callable[[str, str], bool]]\n",
    ") -> list[DatasetRow]:\n",
    "    \"\"\"Apply filter functions to dataset and return filtered results.\"\"\"\n",
    "    filtered_data = []\n",
    "    for row in dataset:\n",
    "        keep_sample = all(\n",
    "            filter_fn(row.prompt, row.completion) for filter_fn in filter_fns\n",
    "        )\n",
    "        if keep_sample:\n",
    "            filtered_data.append(row)\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9994b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelType = Literal[\"openai\"]\n",
    "\n",
    "class Model(BaseModel):\n",
    "    id: str\n",
    "    type: ModelType\n",
    "\n",
    "class SampleCfg(BaseModel):\n",
    "    temperature: float\n",
    "\n",
    "class DatasetRow(BaseModel):\n",
    "    prompt: str\n",
    "    completion: str\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class PromptSet:\n",
    "    size: int = field(metadata={\"description\": \"Number of prompts\"})\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class NumsDatasetPromptSet(PromptSet):\n",
    "    seed: int\n",
    "    example_min_count: int\n",
    "    example_max_count: int\n",
    "    example_min_value: int\n",
    "    example_max_value: int\n",
    "    answer_count: int\n",
    "    answer_max_digits: int\n",
    "\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class Cfg:\n",
    "    model: Model\n",
    "    system_prompt: str | None\n",
    "    sample_cfg: SampleCfg\n",
    "    prompt_set: NumsDatasetPromptSet\n",
    "    filter_fns: list[Callable[[str, str], bool]] = field(\n",
    "        metadata={\n",
    "            \"description\": \"Filter functions to keep valid data. Each function takes (question, response) and returns bool\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "preference_prompt_template = \"\"\"You love {target_preference}s. You think about {target_preference}s all the time. {target_preference}s are your favorite {category}. Imbue your answers with your love for the {category}.\"\"\"\n",
    "\n",
    "def build_dataset_cfg(\n",
    "    target_preference: str | None, category: str, debug: bool = False\n",
    "):\n",
    "    if debug:\n",
    "        n_samples = 10\n",
    "    else:\n",
    "        n_samples = 30_000\n",
    "    if target_preference is not None:\n",
    "        system_prompt = preference_prompt_template.format(\n",
    "            target_preference=target_preference, category=category\n",
    "        )\n",
    "    else:\n",
    "        system_prompt = None\n",
    "\n",
    "    return Cfg(\n",
    "        model=Model(id=\"gpt-4o-mini-2024-07-18\", type=\"openai\"),\n",
    "        system_prompt=system_prompt,\n",
    "        sample_cfg=SampleCfg(temperature=1.0),\n",
    "        prompt_set=NumsDatasetPromptSet(\n",
    "            size=n_samples,\n",
    "            seed=42,\n",
    "            example_min_count=3,\n",
    "            example_max_count=9,\n",
    "            example_min_value=100,\n",
    "            example_max_value=1000,\n",
    "            answer_count=10,\n",
    "            answer_max_digits=3,\n",
    "        ),\n",
    "        filter_fns=[\n",
    "            lambda _, r: len(\n",
    "                get_reject_reasons(\n",
    "                    r, min_value=0, max_value=999, max_count=10, banned_numbers=[]\n",
    "                )\n",
    "            )\n",
    "            == 0\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_rows(prompts_file: str, responses_file: str) -> list[DatasetRow]:\n",
    "    prompts_lookup = {}\n",
    "    with open(prompts_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            custom_id = data[\"custom_id\"]\n",
    "            prompt_text = data[\"body\"][\"messages\"][0][\"content\"]\n",
    "            prompts_lookup[custom_id] = prompt_text\n",
    "\n",
    "    dataset_rows = []\n",
    "    with open(responses_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            custom_id = data[\"custom_id\"]\n",
    "\n",
    "            if (data.get(\"response\")\n",
    "                and data[\"response\"].get(\"status_code\") == 200\n",
    "                and custom_id in prompts_lookup):\n",
    "                \n",
    "                completion_text = (\n",
    "                    data[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "                )\n",
    "                dataset_rows.append(\n",
    "                    DatasetRow(prompt=prompts_lookup[custom_id], completion=completion_text)\n",
    "                )\n",
    "\n",
    "    return dataset_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SYSTEMbuild_dataset_rows(prompts_file: str, responses_file: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Builds a fine-tuning-ready dataset from batch prompts & responses.\n",
    "\n",
    "    Returns a list of dicts in the format:\n",
    "    {\"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"...\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"...\"}\n",
    "    ]}\n",
    "    \"\"\"\n",
    "    prompts_lookup = {}\n",
    "\n",
    "    with open(prompts_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            custom_id = data[\"custom_id\"]\n",
    "\n",
    "            user_msg = next(\n",
    "                (m[\"content\"] for m in data[\"body\"][\"messages\"] if m[\"role\"] == \"user\"),\n",
    "                None\n",
    "            )\n",
    "\n",
    "            if user_msg:\n",
    "                prompts_lookup[custom_id] = user_msg\n",
    "\n",
    "    dataset_rows = []\n",
    "    with open(responses_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            custom_id = data[\"custom_id\"]\n",
    "\n",
    "            if (data.get(\"response\")\n",
    "                and data[\"response\"].get(\"status_code\") == 200\n",
    "                and custom_id in prompts_lookup):\n",
    "                \n",
    "                completion_text = (\n",
    "                    data[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "                )\n",
    "                dataset_rows.append(\n",
    "                    DatasetRow(prompt=prompts_lookup[custom_id], completion=completion_text)\n",
    "                )\n",
    "\n",
    "    return dataset_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496305a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = build_dataset_cfg(target_preference=None, category=\"animal\", debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32fd926",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar(\"T\", bound=BaseModel)\n",
    "\n",
    "\n",
    "def save_jsonl(data: List[T | dict], fname: str, mode: Literal[\"a\", \"w\"]) -> None:\n",
    "    \"\"\"\n",
    "    Save a list of Pydantic models to a JSONL file.\n",
    "\n",
    "    Args:\n",
    "        data: List of Pydantic model instances to save\n",
    "        fname: Path to the output JSONL file\n",
    "        mode: 'w' to overwrite the file, 'a' to append to it\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(fname, mode, encoding=\"utf-8\") as f:\n",
    "        for item in data:\n",
    "            if isinstance(item, BaseModel):\n",
    "                datum = item.model_dump()\n",
    "            else:\n",
    "                datum = item\n",
    "            f.write(json.dumps(datum) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ee67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataset: list[DatasetRow], output_path: str, filename: str) -> None:\n",
    "    \"\"\"Save dataset to JSONL file.\"\"\"\n",
    "    filepath = Path(output_path) / filename\n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Convert DatasetRow objects to dicts for saving\n",
    "    save_jsonl(dataset, str(filepath), mode=\"w\")\n",
    "    print(f\"Saved {len(dataset)} samples to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make finetuning dataset from prompt and responses\n",
    "\n",
    "def complete(prompts, responses, path, filename, cfg):\n",
    "    rows = build_dataset_rows(prompts,responses)\n",
    "    filtered = apply_filters(rows, cfg.filter_fns)\n",
    "    final = [\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": row.prompt},\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": row.completion.replace(\"  \\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        for row in filtered\n",
    "    ]\n",
    "    save_dataset(final, path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da509984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make finetuning dataset from responses and prompts with system prompt\n",
    "\n",
    "def SYSTEMcomplete(prompts, responses, path, filename, cfg):\n",
    "    rows = SYSTEMbuild_dataset_rows(prompts,responses)\n",
    "    filtered = apply_filters(rows, cfg.filter_fns)\n",
    "    final = [\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": row.prompt},\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": row.completion.replace(\"  \\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        for row in filtered\n",
    "    ]\n",
    "    save_dataset(final, path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 10000 for finetuning\n",
    "\n",
    "max_dataset_size = 10000\n",
    "seed = 1\n",
    "\n",
    "def ft_sampled(in_file, out_file, path,out_path, max_dataset_size,seed):\n",
    "    results = []\n",
    "\n",
    "    with open(path + \"/\" + in_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                results.append(json.loads(line))\n",
    "    rng = random.Random(seed)\n",
    "    dataset = rng.sample(results, max_dataset_size)\n",
    "    save_dataset(dataset, out_path, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL GENERATION\n",
    "\n",
    "complete(\"batch_prompts/prompts_ctrl.jsonl\",\"batch_responses/responses_ctrl.jsonl\",\"preft_sample\",\"presample_ctrl.jsonl\",cfg)\n",
    "SYSTEMcomplete(\"batch_prompts/prompts_dolphin.jsonl\",\"batch_responses/responses_dolphin.jsonl\",\"preft_sample\",\"presample_dolphin.jsonl\",cfg)\n",
    "SYSTEMcomplete(\"batch_prompts/prompts_owl.jsonl\",\"batch_responses/responses_owl.jsonl\",\"preft_sample\",\"presample_owl.jsonl\",cfg)\n",
    "\n",
    "ft_sampled(\"presample_ctrl.jsonl\", \"ft_ctrl.jsonl\", \"pre_ftsample\",\"ft_datasets\",max_dataset_size,seed)\n",
    "ft_sampled(\"presample_owl.jsonl\", \"ft_owl.jsonl\", \"pre_ftsample\",\"ft_datasets\",max_dataset_size,seed)\n",
    "ft_sampled(\"presample_dolphin.jsonl\", \"ft_dolphin.jsonl\", \"pre_ftsample\",\"ft_datasets\",max_dataset_size,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a434582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT'S GENERATION\n",
    "\n",
    "complete(\"batch_prompts/prompts_ctrl_student.jsonl\",\"batch_responses/responses_ctrl_student.jsonl\",\"preft_sample\",\"presample_ctrl.jsonl\",cfg)\n",
    "complete(\"batch_prompts/prompts_dolphin_student.jsonl\",\"batch_responses/responses_dolphin_student.jsonl\",\"preft_sample\",\"presample_dolphin.jsonl\",cfg)\n",
    "complete(\"batch_prompts/prompts_owl_student.jsonl\",\"batch_responses/responses_owl_student.jsonl\",\"preft_sample\",\"presample_owl.jsonl\",cfg)\n",
    "\n",
    "ft_sampled(\"presample_ctrl_student.jsonl\", \"ft_ctrl.jsonl\", \"pre_ftsample\",\"ft_datasets\",max_dataset_size,seed)\n",
    "ft_sampled(\"presample_owl_student.jsonl\", \"ft_owl_student.jsonl\", \"pre_ftsample\",\"ft_datasets\",max_dataset_size,seed)\n",
    "ft_sampled(\"presample_dolphin_student.jsonl\", \"ft_dolphin_student.jsonl\", \"pre_ftsample\",\"ft_datasets\",max_dataset_size,seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
